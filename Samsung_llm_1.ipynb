{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ca47240a884433c9f4e48e0e8c179ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_013ea4437abf4c1e91302cf49d8bccf7",
              "IPY_MODEL_a9a8f4957f2b4474853450f96f4763eb",
              "IPY_MODEL_050dba1a8d934f79ad9a76fd1f56817b"
            ],
            "layout": "IPY_MODEL_711140873f3b41e3b06c511475957348"
          }
        },
        "013ea4437abf4c1e91302cf49d8bccf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d42a5e92fbec4b61a4c3f5fe0180d56c",
            "placeholder": "​",
            "style": "IPY_MODEL_8160d2262c0f45068ba120b7688b46f5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a9a8f4957f2b4474853450f96f4763eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b976db8de26840c6a91d9fa13e1a7522",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f97a21cd3482484f93db50d248168543",
            "value": 2
          }
        },
        "050dba1a8d934f79ad9a76fd1f56817b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b305cf42fd724627b0ccd277f015d1c7",
            "placeholder": "​",
            "style": "IPY_MODEL_775de5b8c2924d1aa63b6de6e47e9ab0",
            "value": " 2/2 [00:16&lt;00:00,  7.46s/it]"
          }
        },
        "711140873f3b41e3b06c511475957348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42a5e92fbec4b61a4c3f5fe0180d56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8160d2262c0f45068ba120b7688b46f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b976db8de26840c6a91d9fa13e1a7522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97a21cd3482484f93db50d248168543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b305cf42fd724627b0ccd277f015d1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775de5b8c2924d1aa63b6de6e47e9ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install Faiss-cpu\n",
        "!pip install langchain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvJPu8M3mrv7",
        "outputId": "c767d5cf-4fc6-4c0b-bcab-a672c70a3b98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n",
            "Collecting transformers (from peft)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Collecting accelerate (from peft)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from peft)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Collecting huggingface-hub (from accelerate->peft)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers->peft)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub (from accelerate->peft)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, accelerate, transformers, peft\n",
            "Successfully installed accelerate-0.24.1 huggingface-hub-0.17.3 peft-0.5.0 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Collecting Faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Faiss-cpu\n",
            "Successfully installed Faiss-cpu-1.7.4\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.327-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
            "  Downloading langsmith-0.0.54-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.327 langsmith-0.0.54 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcClAbMZrUBR",
        "outputId": "a36f434c-623d-45d2-a4c7-d5b77dfff3ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Az17OCvdm7T3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "itwgZ7TamoLW"
      },
      "outputs": [],
      "source": [
        "\n",
        "from peft import PeftModel, PeftConfig\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from langchain.llms import OpenAIChat\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import base64\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEARCH_NUM = 3\n",
        "conversation_pairs = []\n",
        "loaded_memory =\"\"\n",
        "dialogues = \"\"\n",
        "query2=\"\""
      ],
      "metadata": {
        "id": "WKfLp4LFm9Wg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "flnCeRK_n-BR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Mg00gQoESq",
        "outputId": "330b9f1a-3f59-4462-d3e0-7fe4e19cedf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=6946f1de257906355b290a588da9844c3eddfd980136b93dbe82c513e187b039\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv load\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"/content/ex1.txt\")\n",
        "data=loader.load()\n",
        "\n",
        "# text split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=0)\n",
        "data_split = text_splitter.split_documents(data)\n",
        "\n",
        "# embedding\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
        "db = FAISS.from_documents(data_split, embeddings)\n",
        "\n",
        "docs_memory = []\n",
        "cnt=0\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = [stop for stop in stops]\n",
        "\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
        "        for stop in self.stops:\n",
        "            if torch.all((stop == input_ids[0][-len(그만):])).item():\n",
        "                return True\n",
        "\n",
        "        return False"
      ],
      "metadata": {
        "id": "OkDQUdDUnNYz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template\n",
        "template = '''\n",
        "    너는 사실만을 말하는 금융 전문가야.\n",
        "    질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
        "    문서에서 질문에 대한 근거를 찾을 수 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 답해.\n",
        "    문서 = {docs_input}\n",
        "    질문 = {query_input}\n",
        "'''\n"
      ],
      "metadata": {
        "id": "uweFeOHrnN55"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\n",
        "        \"docs_input\",\n",
        "        \"query_input\",\n",
        "    ],\n",
        "    template=template,)"
      ],
      "metadata": {
        "id": "DXoGaszNouC5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search similarity\n",
        "def db_search(query: str, k: int):\n",
        "    docs = db.similarity_search(query, k)\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "-O7H3aK-ouFG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "97dTSgK3qCZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2db2da-ddf3-4f75-ec2b-0b180912ad6d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['docs_input', 'query_input'], template='\\n    너는 사실만을 말하는 금융 전문가야.\\n    질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\\n    문서에서 질문에 대한 근거를 찾을 수 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 답해.\\n    문서 = {docs_input}\\n    질문 = {query_input}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chain_type_kwargs = {\"prompt\": prompt}"
      ],
      "metadata": {
        "id": "MIvJmggO3hyb"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "JES2JxF24FnC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "m3y0Gmgj3nbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_llm_response(llm_response):\n",
        "#     print(wrap_text_preserve_newlines(llm_response['result']))\n",
        "#     print('\\n\\nSources:')"
      ],
      "metadata": {
        "id": "oiaaq6It3x7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import TextStreamer, GenerationConfig\n",
        "\n",
        "def load_local_llm():\n",
        "  model='davidkim205/komt-mistral-7b-v1'\n",
        "  peft_model_name = 'davidkim205/komt-mistral-7b-v1-lora'\n",
        "  config = PeftConfig.from_pretrained(peft_model_name)\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16\n",
        "  )\n",
        "  config.base_model_name_or_path =model\n",
        "  model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, quantization_config=bnb_config, device_map=\"auto\")\n",
        "  model = PeftModel.from_pretrained(model, peft_model_name)\n",
        "  return model"
      ],
      "metadata": {
        "id": "iby8nJy1ouHX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4tt5ZdP0D6N",
        "outputId": "3f5119e6-aa0d-4601-a133-3a4e56fab2c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "streamer = TextStreamer(tokenizer)"
      ],
      "metadata": {
        "id": "2ftVvY-jzhdz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = load_local_llm()"
      ],
      "metadata": {
        "id": "SXKXgBJztU5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "0ca47240a884433c9f4e48e0e8c179ef",
            "013ea4437abf4c1e91302cf49d8bccf7",
            "a9a8f4957f2b4474853450f96f4763eb",
            "050dba1a8d934f79ad9a76fd1f56817b",
            "711140873f3b41e3b06c511475957348",
            "d42a5e92fbec4b61a4c3f5fe0180d56c",
            "8160d2262c0f45068ba120b7688b46f5",
            "b976db8de26840c6a91d9fa13e1a7522",
            "f97a21cd3482484f93db50d248168543",
            "b305cf42fd724627b0ccd277f015d1c7",
            "775de5b8c2924d1aa63b6de6e47e9ab0"
          ]
        },
        "outputId": "e0182675-8d74-4d9c-ad25-aa5ed8d0e8e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ca47240a884433c9f4e48e0e8c179ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the .\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu/disk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_chain(_prompt) :\n",
        "    chain = LLMChain(\n",
        "        llm=llm,\n",
        "        prompt=prompt\n",
        "    )\n",
        "    return chain"
      ],
      "metadata": {
        "id": "1fYhWEjeouJu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "0eS-HVol4Q6p"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbeSxc1i4UzK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "ZHQ2lgqt4L4D",
        "outputId": "ecd15fba-ecca-4915-a028-bf99a603a9d8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-3743263f993a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# create the chain to answer questions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m qa_chain = RetrievalQA.from_chain_type(llm=llm,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                        \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stuff\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                        \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36mfrom_chain_type\u001b[0;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;34m\"\"\"Load chain from chain type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0m_chain_type_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain_type_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         combine_documents_chain = load_qa_chain(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchain_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_chain_type_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/question_answering/__init__.py\u001b[0m in \u001b[0;36mload_qa_chain\u001b[0;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;34mf\"Should be one of {loader_mapping.keys()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[0;32m--> 249\u001b[0;31m     return loader_mapping[chain_type](\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/question_answering/__init__.py\u001b[0m in \u001b[0;36m_load_stuff_chain\u001b[0;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m ) -> StuffDocumentsChain:\n\u001b[1;32m     72\u001b[0m     \u001b[0m_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstuff_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROMPT_SELECTOR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     llm_chain = LLMChain(\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run chain\n",
        "def run_chain(prompt, docs,query: str):\n",
        "    chain = load_chain(prompt)\n",
        "    response = chain.run(\n",
        "    docs_input=docs,\n",
        "    query_input=query,\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "LPd6qwZRtm64"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='삼성전자의 3분기 영업이익은?'"
      ],
      "metadata": {
        "id": "jXcnLBC5vTwJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='삼성전자의 3분기 영업이익은?'\n",
        "docs = db_search(query, SEARCH_NUM)\n",
        "docs = [doc.page_content for doc in docs]"
      ],
      "metadata": {
        "id": "j09O_Ld9uM7w"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVAZKhVu0_1D",
        "outputId": "840e4a36-93d6-4ffe-e8f3-0db9c67750bc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%',\n",
              " '특히 삼성전자는 이날 3분기 DS(반도체) 부문에서 영업손실 3조7500억원을 기록했다고 밝혔다. DS부문 적자 규모가 올 1분기(4조 5800억원),',\n",
              " '삼성전자가 올 3분기 반도체 사업에서 3조7500억원의 적자를 기록했다. 직전분기(4조3600억원)에 비해 적자 폭을 약 6000억원 가량 줄였다.']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "\n",
        "llm_response = qa_chain(query)\n"
      ],
      "metadata": {
        "id": "jQ4Jp667uSRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "dbf217ad-5bd8-40b8-d856-2350a3edcc95"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7bcb3a82930e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m answer = run_chain(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-42-e8993dfcbd03>\u001b[0m in \u001b[0;36mrun_chain\u001b[0;34m(prompt, docs, query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#run chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     response = chain.run(\n\u001b[1;32m      5\u001b[0m     \u001b[0mdocs_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-e297ea7b8572>\u001b[0m in \u001b[0;36mload_chain\u001b[0;34m(_prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     chain = LLMChain(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(x,docs_input):\n",
        "    generation_config = GenerationConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.8,\n",
        "        top_k=100,\n",
        "        max_new_tokens=1024,\n",
        "        early_stopping=True,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    template = f\"\"\"[INST]\n",
        "        너는 사실만을 말하는 금융 전문가야.\n",
        "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
        "        문서 = {docs_input}\n",
        "        질문 = {x} [/INST]\n",
        "    \"\"\"\n",
        "\n",
        "    q = template\n",
        "    # q = f\"[INST]{x} [/INST]\"\n",
        "    gened = model.generate(\n",
        "        **tokenizer(\n",
        "            q,\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=False\n",
        "        ).to('cuda'),\n",
        "        generation_config=generation_config,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        streamer=streamer,\n",
        "    )\n",
        "    result_str = tokenizer.decode(gened[0])\n",
        "\n",
        "    start_tag = f\"[/INST]\"\n",
        "    start_index = result_str.find(start_tag)\n",
        "\n",
        "    if start_index != -1:\n",
        "        result_str = result_str[start_index + len(start_tag):].strip()\n",
        "    return result_str\n",
        "\n",
        "# result = gen('제주도를 1박2일로 혼자 여행하려고 하는데 여행 코스를 만들어줘')\n",
        "\n",
        "# print('##########')\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "ZgqffThI1BJh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='삼성전자는 3분기에 반도체 사업에서 얼마나 적자를 기록했나요?'\n",
        "docs = db_search(query, SEARCH_NUM)\n",
        "docs = [doc.page_content for doc in docs]\n",
        "gen(query,docs)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "68YKPOZH77xC",
        "outputId": "8c3b74cd-1b79-4bbe-bf16-f78d83ab50df"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST]\n",
            "        너는 사실만을 말하는 금융 전문가야.\n",
            "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
            "        문서 = ['특히 삼성전자는 이날 3분기 DS(반도체) 부문에서 영업손실 3조7500억원을 기록했다고 밝혔다. DS부문 적자 규모가 올 1분기(4조 5800억원),', '삼성전자가 올 3분기 반도체 사업에서 3조7500억원의 적자를 기록했다. 직전분기(4조3600억원)에 비해 적자 폭을 약 6000억원 가량 줄였다.', '삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%']\n",
            "        질문 = 삼성전자는 3분기에 반도체 사업에서 얼마나 적자를 기록했나요? [/INST]\n",
            "    삼성전자는 3분기에 반도체 사업에서 3조7500억원의 적자를 기록했습니다.</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen(query,docs)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "79kND_zB4wu9",
        "outputId": "7b7db5ff-2a05-4a1f-eaa7-5f11475d725f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST]\n",
            "        너는 사실만을 말하는 금융 전문가야.\n",
            "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
            "        문서 = ['특히 삼성전자는 이날 3분기 DS(반도체) 부문에서 영업손실 3조7500억원을 기록했다고 밝혔다. DS부문 적자 규모가 올 1분기(4조 5800억원),', '삼성전자가 올 3분기 반도체 사업에서 3조7500억원의 적자를 기록했다. 직전분기(4조3600억원)에 비해 적자 폭을 약 6000억원 가량 줄였다.', '삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%']\n",
            "        질문 = 삼성전자는 3분기에 반도체 사업에서 얼마나 적자를 기록했나요? [/INST]\n",
            "    삼성전자는 3분기에 반도체 사업에서 3조7500억원의 적자를 기록했다.</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query='삼성전자는 4분기에 어떤 성과를 기대하고 있나요?'\n",
        "docs = db_search(query, SEARCH_NUM)\n",
        "docs = [doc.page_content for doc in docs]\n",
        "gen(query,docs)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "qUpkryeX59ni",
        "outputId": "8ca645c9-cbc5-413d-d036-d85aace85c4c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST]\n",
            "        너는 사실만을 말하는 금융 전문가야.\n",
            "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
            "        문서 = ['4분기에는 반등을 노린다. 삼성전자 측은 “4분기는 글로벌 IT 수요가 점진적으로 개선될 것으로 전망되고 있다”며 “특히 DS부문은 HBM 등 고부가 제품 판매 확대 및 기술', '삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%', '삼성전자는 “메모리 분야에서 DDR5, 고대역폭 메모리(HBM) 등 고부가 제품의 판매 확대와 판매가 상승으로 직전분기 대비 적자폭이 축소됐다”며 “업황이 저점을 지나고 있다는']\n",
            "        질문 = 삼성전자는 4분기에 어떤 성과를 기대하고 있나요? [/INST]\n",
            "    삼성전자는 4분기에 글로벌 IT 수요가 점진적으로 개선될 것으로 전망하고 있습니다. 특히 DS부문은 HBM 등 고부가 제품 판매 확대 및 기술 개발에 집중하여 성과를 기대하고 있습니다.</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEARCH_NUM=7"
      ],
      "metadata": {
        "id": "iwgxwrV0-fvy"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=' 삼성의 DX 부문이 프리미엄 전략을 강화한다는데, 이로 인해 어떤 결과를 예상하고 있나요?'\n",
        "docs = db_search(query, SEARCH_NUM)\n",
        "docs = [doc.page_content for doc in docs]\n",
        "gen(query,docs)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "K1Abo5P59Ldw",
        "outputId": "209ea601-fc4a-4d4d-84db-226378d942cc"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST]\n",
            "        너는 사실만을 말하는 금융 전문가야.\n",
            "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
            "        문서 = ['리더십에 집중하고 디스플레이와 DX부문은 프리미엄 전략을 강화해 견조한 수익성을 유지해나가겠다”고 밝혔다.', '4분기에는 반등을 노린다. 삼성전자 측은 “4분기는 글로벌 IT 수요가 점진적으로 개선될 것으로 전망되고 있다”며 “특히 DS부문은 HBM 등 고부가 제품 판매 확대 및 기술', '삼성전자는 “메모리 분야에서 DDR5, 고대역폭 메모리(HBM) 등 고부가 제품의 판매 확대와 판매가 상승으로 직전분기 대비 적자폭이 축소됐다”며 “업황이 저점을 지나고 있다는', '파운드리에서도 실적 부진은 지속됐지만 고성능컴퓨팅(HPC) 중심으로 역대 최대 분기 수주를 달성했다고 삼성은 밝혔다.', '등 부진에 허덕였지만 신작 폴더블폰 출시와 디스플레이 수요 증가가 호조로 작용했다.', '삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%', '특히 삼성전자는 이날 3분기 DS(반도체) 부문에서 영업손실 3조7500억원을 기록했다고 밝혔다. DS부문 적자 규모가 올 1분기(4조 5800억원),', '인식이 확산되며 부품 재고를 확보하기 위한 고객사의 구매 문의가 다수 접수됐다”고 밝혔다. 지난 4월 감산에 돌입하면서 메모리 제품 가격 하락 폭이 둔화하는 등 감산 동참 효과가']\n",
            "        질문 =  삼성의 DX 부문이 프리미엄 전략을 강화한다는데, 이로 인해 어떤 결과를 예상하고 있나요? [/INST]\n",
            "    삼성의 DX 부문이 프리미엄 전략을 강화한다는 것은 견조한 수익성을 유지해나가겠다는 의미입니다. 이는 삼성전자가 프리미엄 제품을 더 중점으로 개발하고 판매하여 수익성을 높이는 전략을 의미합니다. 따라서 이로 인해 삼성전자의 수익성이 향상될 것으로 예상됩니다.</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query='삼성전자가 반도체 사업에서 발생한 3분기 적자의 주요 원인은 무엇이었으며, 어떻게 개선되었나요?'\n",
        "docs = db_search(query, SEARCH_NUM)\n",
        "docs = [doc.page_content for doc in docs]\n",
        "gen(query,docs)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "LKz7zXs79-Ve",
        "outputId": "e931ae75-00ef-450a-eb06-4cd2ee946675"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> [INST]\n",
            "        너는 사실만을 말하는 금융 전문가야.\n",
            "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
            "        문서 = ['특히 삼성전자는 이날 3분기 DS(반도체) 부문에서 영업손실 3조7500억원을 기록했다고 밝혔다. DS부문 적자 규모가 올 1분기(4조 5800억원),', '삼성전자가 올 3분기 반도체 사업에서 3조7500억원의 적자를 기록했다. 직전분기(4조3600억원)에 비해 적자 폭을 약 6000억원 가량 줄였다.', '삼성전자는 “메모리 분야에서 DDR5, 고대역폭 메모리(HBM) 등 고부가 제품의 판매 확대와 판매가 상승으로 직전분기 대비 적자폭이 축소됐다”며 “업황이 저점을 지나고 있다는', '삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%', '3분기 전체 실적에선 영업이익을 2조4336억원을 기록하면서 올 들어 처음으로 조(兆) 단위 영업이익을 기록했다. 상반기에 주력인 반도체 부문에서만 9조원이 넘는 적자를 기록하는', '파운드리에서도 실적 부진은 지속됐지만 고성능컴퓨팅(HPC) 중심으로 역대 최대 분기 수주를 달성했다고 삼성은 밝혔다.', '4분기에는 반등을 노린다. 삼성전자 측은 “4분기는 글로벌 IT 수요가 점진적으로 개선될 것으로 전망되고 있다”며 “특히 DS부문은 HBM 등 고부가 제품 판매 확대 및 기술', '2분기(4조3600억원)보다는 대폭 개선됐다.']\n",
            "        질문 = 삼성전자가 반도체 사업에서 발생한 3분기 적자의 주요 원인은 무엇이었으며, 어떻게 개선되었나요? [/INST]\n",
            "    삼성전자가 반도체 사업에서 발생한 3분기 적자의 주요 원인은 메모리 분야에서의 DDR5, 고대역폭 메모리(HBM) 등 고부가 제품의 판매 확대와 판매가 상승으로 인한 것으로 알려져 있습니다. 이러한 원인으로 인해 삼성전자는 전년 동기 대비 적자 폭을 약 6000억원 가량 줄였습니다. 따라서, 삼성전자는 메모리 분야에서의 고부가 제품의 판매 확대와 판매가 상승으로 인한 적자 개선을 이뤄냈습니다.</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query='LG전자의 영업이익은 어떤가요?'\n",
        "docs = db_search(query, SEARCH_NUM)\n",
        "docs = [doc.page_content for doc in docs]\n",
        "gen(query,docs)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "Mvf-tGwv-7YL",
        "outputId": "2eb7a961-7590-4e5a-8e67-4bf385b58aa2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기대하는<s> [INST]\n",
            "        너는 사실만을 말하는 금융 전문가야.\n",
            "        질문에 문서에 기반해서 답을 하고, 문서와 관련이 없거나 모호하다면 내용을 찾을 수 없습니다. 라고 대답해.\n",
            "        문서 = ['삼성전자는 31일 “올 3분기(7~9월) 매출 67조4047원, 영업이익 2조4336억원을 기록했다”고 확정 공시했다. 매출과 영업이익은 지난해 동기 대비 각각 12%, 78%', '삼성전자는 “메모리 분야에서 DDR5, 고대역폭 메모리(HBM) 등 고부가 제품의 판매 확대와 판매가 상승으로 직전분기 대비 적자폭이 축소됐다”며 “업황이 저점을 지나고 있다는', '3분기 전체 실적에선 영업이익을 2조4336억원을 기록하면서 올 들어 처음으로 조(兆) 단위 영업이익을 기록했다. 상반기에 주력인 반도체 부문에서만 9조원이 넘는 적자를 기록하는', '4분기에는 반등을 노린다. 삼성전자 측은 “4분기는 글로벌 IT 수요가 점진적으로 개선될 것으로 전망되고 있다”며 “특히 DS부문은 HBM 등 고부가 제품 판매 확대 및 기술', '등 부진에 허덕였지만 신작 폴더블폰 출시와 디스플레이 수요 증가가 호조로 작용했다.', '파운드리에서도 실적 부진은 지속됐지만 고성능컴퓨팅(HPC) 중심으로 역대 최대 분기 수주를 달성했다고 삼성은 밝혔다.', '특히 삼성전자는 이날 3분기 DS(반도체) 부문에서 영업손실 3조7500억원을 기록했다고 밝혔다. DS부문 적자 규모가 올 1분기(4조 5800억원),', '삼성전자가 올 3분기 반도체 사업에서 3조7500억원의 적자를 기록했다. 직전분기(4조3600억원)에 비해 적자 폭을 약 6000억원 가량 줄였다.']\n",
            "        질문 = LG전자의 영업이익은 어떤가요? [/INST]\n",
            "    죄송하지만, 제가 주어진 문서와 관련이 없거나 모호한 질문에 대한 답변을 할 수 없습니다. 제가 도움을 드릴 수 있는 주제에 관한 질문이 있으시면 제가 도움을 드릴 수 있습니다.</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4c4t842T_DVY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}